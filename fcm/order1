#!/usr/bin/perl

# First-order finite context modeling.
# The idea here is that the meaning of words can be determined by their contexts; i.e. which words come before and which words come after them. There are two ways to see this. One is to treat
# every pair of words as an element in a similarity relation, so if 'barking' is followed by 'dog', then 'barking' is similar to 'dog'. The other way to look at it is by replaceability; if
# 'barking' is followed by both 'dog' and 'cat', then 'dog' and 'cat' have in common that they can be barking.

#   Asymmetry.
#   Word order is significant in English, so there are two separate models built. One is for preceding words, and the other is for following. (e.g. in the sentence 'foo bar', 'foo' precedes
#   'bar', which follows 'foo'.) Similarity is ultimately a symmetric measure, but we can change the relative contribution of precedence vs. following. So while the factors of the relation are
#   asymmetric regarding the original placement of the words, the ultimate relation should end up being symmetric.

#   Proximity vs. replaceability.
#   It's important to be able to distinguish these two measurements. The simplest way to go about this is to record the frequencies of all observed word pairs. Given this information, we can
#   compute the preceding-proximity as the P(x precedes y) in the sample, and the the preceding replaceability is P(x precedes z -> y precedes z, forall z).

# Indexing.
# There are two files that get created per block. The first is a 'before' file; it lists each word and all of the words that precede it at some point, along with their frequency. The second is
# an 'after' file; it does the same, but for followers. So, for instance, if 'foo' ultimately is preceded by 'bar', 'bif', and 'baz', then there will be a record in the 'before' file containing
# the text 'foo bar n1 bif n2 baz n3' -- here, n1, n2, and n3 indicate how many times 'foo' was preceded by each word. The records are sorted, but the terms on each line are not necessarily
# sorted.

mkdir 'blocks';

my %second_words_for;
my %first_words_for;
my $i = 0;
my $block_size = 10000;

sub write_file {
  my ($filename, $thunk) = @_;
  open my $fh, '>', $filename;
  &$thunk(sub {print $fh @_});
  close $fh;
}

my $block_number = 0;
my $write_batch = sub {
  ++$block_number;
  print STDERR "Writing block $block_number\n";

  write_file "blocks/before-$block_number", sub {&{$_[0]}("$_ " . join(' ', %{$second_words_for{$_}}), "\n") for sort keys %second_words_for};
  write_file "blocks/after-$block_number",  sub {&{$_[0]}("$_ " . join(' ', %{$first_words_for{$_}}),  "\n") for sort keys %first_words_for};
  %second_words_for = %first_words_for = ();
};

for (<>) {
  my @words = split;
  ++$second_words_for{$words[$_]}{$words[$_ + 1]} and ++$first_words_for{$words[$_ + 1]}{$words[$_]} for 0 .. $#words - 1;
  &$write_batch() unless ++$i % $block_size;
}

&$write_batch();

# Generated by SDoc 
