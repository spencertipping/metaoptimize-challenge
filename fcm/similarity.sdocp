sdocp('similarity.sdoc', '#!/usr/bin/perl\n\nBlocked similarity scorer.\nThe idea here is to score each word based on a single block at a time. We write the intermediate results to a new set of files, and the final results are compiled from those. This program\ntakes the before and after blocks, and computes connected-before and connected-after sets. These indicate replaceability.\n\nThere are a few different ways we can measure this. Given that we\'re trying to make a statement about probabilities (i.e. which word is the most likely replacement for this other word), we\nneed to take a few things into account:\n\n| 1. How frequently does the connective word appear? (e.g. if \'the\' connects two words, it means very little; but if \'proboscis\' connects them, that means a lot)\n  2. Given that one word appears, what can we assume about the other word? This one is interesting. Suppose that eight out of ten times the word \'proboscis\' is followed by \'monkey\', once it\'s\n     followed by \'zucchini\', and the other time it\'s followed by \'penguin\'. We can obviously make the case that penguins, zucchini, and monkeys have probosci in common, but perhaps more\n     importantly we can say that the relation between penguins and monkeys is stronger than the one between penguins and zucchinis. We can say this because \'proboscis\' is more suggestive of\n     \'monkey\' than it is of \'zucchini\', and it\'s responsible for the linkage between \'penguin\' and the two other words in the first place. (We\'re approximating transitivity through\n     before/after relations.)\n  3. Transitive closure: Given that word X replaces word Y with probability P, word X\' following X and word Y\' following Y are also replaceable with some probability bounded above by P. For\n     notational convenience, I use the \'r\' operator to indicate replacement and the \'f\' operator to indicate following. So if P(X r Y) = p1, P(X\' f X) = p2, and P(Y\' f Y) = p3, then P(X\' r Y\')\n     = p1 * p2 * p3. (It\'s actually not quite so simple, since we also have preceding words. In practice there are five probability constants, and the preceding/following ones are relatively\n     weighted.)\n\nTo keep things feasible I\'m not going to worry too much about transitive closure; maybe one iteration or so, but it happens after the other steps. (Interestingly, I think a sparse matrix\nexponentiation actually computes this for you once the other quantities are normalized.) The purpose of this program is mainly to read words from the vocabulary table, note their frequency,\nand compute normalized likelihoods of replacement for each one.\n\nImplementation.\nThe program is implemented a bit backwards. We read the vocabulary words into a hash, where each word points to its frequency. Then we go through the before and after blocks sequentially. For\neach connected word we compute the replaceability with each other connected word, noting the frequency of the connector. We end up with a table that looks like this:\n\n| monkey proboscis 10 penguin 1 zucchini 1\n  penguin proboscis 10 monkey 8 zucchini 1\n  zucchini proboscis 10 monkey 8 penguin 1\n\nThis ends up scoring things based on similarity. We later use a hierarchical merge to combine similarities into a final result.\n\nThere\'s an arbitrary cutoff on the connective word\'s frequency. If it\'s above a certain threshold, we don\'t consider it because it will have almost no impact on the results. Same for the\nlinkages; words with too many alternative linkages will create huge files and contain little information.\n\nmy $maximum_frequency = 1000;\nmy $maximum_linkages  = 20;\n\nmy @blocks = <blocks/*>;\n\nprint STDERR "Reading vocabulary\\n";\nopen my $vocabulary_file, \'<\', \'../vocabulary.txt\';\nmy %vocabulary = map /(\\d+) (.*)$/ ? ($2, $1) : (), <$vocabulary_file>;\nclose $vocabulary_file;\n\nfor (grep ! /-connected$/, @blocks) {\n  print STDERR "Processing $_\\n";\n\n  open my $block, \'<\', $_;\n  open my $new_block, \'>\', "$_-connected";\n  for (<$block>) {\n    my ($w, %links) = split;\n    my ($count, $links) = ($vocabulary{$w}, scalar(keys %links));\n    if ($count and $count < $maximum_frequency and $links > 1 and $links < $maximum_linkages) {\n      for my $k (keys %links) {\n        print $new_block "$k $w $count ", join(\' \', map "$_ $links{$_}", grep $_ ne $k, keys %links), "\\n";\n      }\n    }\n  }\n  close $new_block;\n  close $block;\n}\n');