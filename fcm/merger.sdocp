sdocp('merger.sdoc', '#!/usr/bin/perl\n\nBlock merger.\nThis utility merges blocks by twos. Because it\'s the reduction step, all of the configuration goes here as well. Basically we take subsequent pairs of blocks from some directory (the blocks\ncan be of any size) and merge them into larger ones, discarding information in the process. While it is true that we will have arbitrarily many records this way, we can bound the size of each\none through a reduction step. This reduction step involves taking the ten most relevant words at any given point. Because we combine them only two at a time, this will ultimately be a fairly\naccurate reflection of the actual similarity. (That is, we won\'t drop very many high-similarity words prematurely, though we will probably lose some.)\n\n  Merging normalized records.\n  This is surprisingly easy. Given two records:\n\n  | w1 c11 p11 c12 p12 ...\n    w1 c21 p21 c22 p22 ...\n\n  We simply add the pij quantities for equal cij\'s, otherwise we leave them separate. Then we sort for greatest pij quantities and keep the first ten words. This new record will have the same\n  format as the old one, but only the most relevant words will remain.\n\nCoefficients.\nWe need to configure sensible coefficients to determine how much each block contributes to the final result. For example, English text usually places adjectives before nouns; so it would make\nsense for before- blocks to contribute more heavily than after- blocks. This isn\'t necessarily true for the before-connected and after-connected blocks; because we run one step in each\ndirection, these should be roughly equivalent.\n\nmy $absolute_connected_before = 0.25;\nmy $absolute_connected_after  = 0.25;\nmy $absolute_adjacent_before  = 0.35;\nmy $absolute_adjacent_after   = 0.15;\n\nBlocks to be merged are provided as command-line arguments and are written to stdout. We infer the coefficient from the block name; if it\'s a nonstandard name, then we assume it\'s output from\nthis program and we don\'t apply a multiplier. (This is evidence that I should have put the coefficient logic into the normalizer; oh well...)\n\nmy %records;\nfor (@ARGV) {\n  my $coefficient = /before-/ && /-connected$/ ? $absolute_connected_before :\n                    /after-/ &&  /-connected$/ ? $absolute_connected_after :\n                    /before-/                  ? $absolute_adjacent_before :\n                    /after-/                   ? $absolute_adjacent_after : 1;\n\n  print STDERR "Reading $_ with coefficient $coefficient\\n";\n  open my $file, \'<\', $_;\n  for (<$file>) {\n    my ($w, %links) = split;\n    $records{$w} ||= {};\n    $records{$w}{$_} += $links{$_} * $coefficient for keys %links;\n  }\n  close $file;\n}\n\nNow write the new normalized records in sorted order:\n\nfor my $w (sort keys %records) {\n  my %record = %{$records{$w}};\n  my @keys   = sort {$record{$b} <=> $record{$a}} keys %record;\n  print "$w ", join(\' \', map "$_ $record{$_}", grep defined, @keys[0 .. 9]), "\\n";\n}\n');